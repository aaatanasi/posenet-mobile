<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"
  />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <title>PoseNet Mobile Simple</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    body {
      background: #000;
      height: 100vh;
      overflow: hidden;
      font-family: -apple-system, BlinkMacSystemFont, sans-serif;
      color: #fff;
    }
    #container {
      position: fixed;
      inset: 0;
      display: flex;
      justify-content: center;
      align-items: center;
      background: #000;
    }
    #canvas {
      width: 100vw;
      height: 100vh;
      display: block;
    }
    #video {
      display: none;
    }
    #loading {
      position: fixed;
      top: 20px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0, 0, 0, 0.85);
      padding: 10px 16px;
      border-radius: 16px;
      font-size: 15px;
      z-index: 10;
    }
    #controls {
      position: fixed;
      bottom: 30px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 10;
      display: flex;
      flex-direction: column;
      gap: 10px;
      align-items: center;
    }
    button {
      padding: 14px 24px;
      background: rgba(0, 122, 255, 0.95);
      color: #fff;
      border: 0;
      border-radius: 24px;
      font-size: 15px;
      font-weight: 600;
      min-width: 180px;
    }
    .secondary-btn {
      background: rgba(255, 255, 255, 0.2);
      padding: 10px 18px;
      font-size: 13px;
      min-width: auto;
    }
    .hidden {
      display: none;
    }
    #stats {
      position: fixed;
      top: 60px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0, 0, 0, 0.7);
      padding: 6px 10px;
      border-radius: 12px;
      font-size: 12px;
      z-index: 10;
    }
    .value {
      color: #0ff;
      font-weight: 700;
    }
  </style>
</head>
<body>
  <div id="container">
    <div id="loading">Loading AI modelâ€¦</div>

    <div id="stats" class="hidden">
      People: <span id="peopleCount" class="value">0</span> |
      FPS: <span id="fps" class="value">0</span> |
      Keypoints: <span id="keypointCount" class="value">0</span>
    </div>

    <video id="video" playsinline autoplay muted></video>
    <canvas id="canvas"></canvas>

    <div id="controls">
      <button id="startBtn" disabled>Start Camera</button>
      <button id="flipBtn" class="secondary-btn hidden">Flip Camera</button>
    </div>
  </div>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <!-- PoseNet -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet@2.2.1/dist/posenet.min.js"></script>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const loadingEl = document.getElementById("loading");
    const startBtn = document.getElementById("startBtn");
    const flipBtn = document.getElementById("flipBtn");
    const statsEl = document.getElementById("stats");
    const fpsEl = document.getElementById("fps");
    const peopleCountEl = document.getElementById("peopleCount");
    const keypointCountEl = document.getElementById("keypointCount");

    let net = null;
    let previousKeypoints = null;
    const smoothingFactor = 0.5;

    let isRunning = false;
    let facingMode = "user";
    let stream = null;

    // Lower confidence for mobile
    let minConfidence = 0.05;

    let lastFrameTime = performance.now();
    let frames = 0;

    function resizeCanvasToVideo() {
      if (!video.videoWidth || !video.videoHeight) return;
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      console.log("Canvas size:", canvas.width, canvas.height);
    }

    async function setupCamera() {
      if (stream) {
        stream.getTracks().forEach((t) => t.stop());
      }
      video.srcObject = null;
      stream = null;
      await new Promise((r) => setTimeout(r, 200));

      const constraints = {
        audio: false,
        video: {
          facingMode,
          width: { ideal: 1280 },
          height: { ideal: 720 },
        },
      };

      stream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = stream;

      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          video.play();
          setTimeout(() => {
            resizeCanvasToVideo();
            console.log(
              "Camera ready:",
              facingMode,
              video.videoWidth,
              "x",
              video.videoHeight
            );
            resolve();
          }, 300);
        };
      });
    }

    function smoothKeypoints(keypoints) {
      if (!previousKeypoints) {
        previousKeypoints = keypoints.map((kp) => ({
          ...kp,
          position: { ...kp.position },
        }));
        return keypoints;
      }
      const smoothed = keypoints.map((kp, i) => {
        const prev = previousKeypoints[i] || kp;
        return {
          ...kp,
          position: {
            x:
              prev.position.x * smoothingFactor +
              kp.position.x * (1 - smoothingFactor),
            y:
              prev.position.y * smoothingFactor +
              kp.position.y * (1 - smoothingFactor),
          },
        };
      });
      previousKeypoints = smoothed.map((kp) => ({
        ...kp,
        position: { ...kp.position },
      }));
      return smoothed;
    }

    function drawKeypoints(keypoints, minConf) {
      let count = 0;
      keypoints.forEach((kp, i) => {
        if (kp.score < minConf) return;
        count++;

        const x = kp.position.x;
        const y = kp.position.y;

        if (i === 0) {
          console.log(
            `Keypoint 0: (${x.toFixed(0)}, ${y.toFixed(
              0
            )}), score: ${kp.score.toFixed(2)}`
          );
        }

        ctx.beginPath();
        ctx.arc(x, y, 10, 0, 2 * Math.PI);
        ctx.fillStyle = "#00ff00";
        ctx.fill();
        ctx.strokeStyle = "#ffffff";
        ctx.lineWidth = 3;
        ctx.stroke();
      });
      return count;
    }

    function drawSkeleton(keypoints, minConf) {
      const adjacent = posenet.getAdjacentKeyPoints(keypoints, minConf);

      console.log("Skeleton connections:", adjacent.length);

      adjacent.forEach(([a, b]) => {
        const x1 = a.position.x;
        const y1 = a.position.y;
        const x2 = b.position.x;
        const y2 = b.position.y;

        ctx.beginPath();
        ctx.moveTo(x1, y1);
        ctx.lineTo(x2, y2);
        ctx.lineWidth = 5;
        ctx.strokeStyle = "#00ffff";
        ctx.stroke();
      });
    }

    function updateFPS() {
      frames++;
      const now = performance.now();
      const elapsed = now - lastFrameTime;
      if (elapsed >= 1000) {
        const fps = Math.round((frames * 1000) / elapsed);
        fpsEl.textContent = String(fps);
        frames = 0;
        lastFrameTime = now;
      }
    }

    async function detectPose() {
      if (!net || !isRunning) return;

      const pose = await net.estimateSinglePose(video, {
        flipHorizontal: facingMode === "user", // for front camera
      });

      const smoothed = smoothKeypoints(pose.keypoints);
      peopleCountEl.textContent = pose.score > 0.1 ? "1" : "0";

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Draw video into canvas
      if (facingMode === "user") {
        // Mirror entire canvas for selfie
        ctx.save();
        ctx.translate(canvas.width, 0);
        ctx.scale(-1, 1);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        ctx.restore();
      } else {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      }

      // Draw skeleton in canvas coordinate space
      const keypointCount = drawKeypoints(smoothed, minConfidence);
      drawSkeleton(smoothed, minConfidence);

      keypointCountEl.textContent = String(keypointCount);

      updateFPS();
      requestAnimationFrame(detectPose);
    }

    startBtn.addEventListener("click", async () => {
      try {
        startBtn.disabled = true;
        loadingEl.textContent = "Starting camera...";
        await setupCamera();
        loadingEl.textContent = "Move around! ðŸ‘‹";
        statsEl.classList.remove("hidden");
        flipBtn.classList.remove("hidden");
        startBtn.classList.add("hidden");
        isRunning = true;
        detectPose();
      } catch (err) {
        console.error(err);
        loadingEl.textContent = "Camera error: " + err.message;
        startBtn.disabled = false;
      }
    });

    flipBtn.addEventListener("click", async () => {
      try {
        flipBtn.disabled = true;
        loadingEl.textContent = "Switching camera...";
        isRunning = false;

        facingMode = facingMode === "user" ? "environment" : "user";
        previousKeypoints = null;

        await setupCamera();

        loadingEl.textContent = "Move around! ðŸ‘‹";
        flipBtn.disabled = false;
        isRunning = true;
        detectPose();
      } catch (err) {
        console.error(err);
        loadingEl.textContent = "Camera flip error";
        flipBtn.disabled = false;
        isRunning = true;
        detectPose();
      }
    });

    async function init() {
      try {
        loadingEl.textContent = "Loading AI modelâ€¦";
        await tf.setBackend("webgl");
        await tf.ready();

        net = await posenet.load({
          architecture: "MobileNetV1",
          outputStride: 16,
          inputResolution: { width: 353, height: 353 },
          multiplier: 0.75,
        });

        loadingEl.textContent = "Ready! Tap Start Camera";
        startBtn.disabled = false;
      } catch (err) {
        console.error(err);
        loadingEl.textContent = "Model loading error";
      }
    }

    init();
  </script>
</body>
</html>
