<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <title>PoseNet Mobile</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    body {
      background: #000;
      height: 100vh;
      overflow: hidden;
      font-family: -apple-system, BlinkMacSystemFont, sans-serif;
      color: white;
    }
    #container {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
    #video {
      display: none;
    }
    #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
    #loading {
      position: fixed;
      top: 20px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0,0,0,0.85);
      padding: 15px 25px;
      border-radius: 20px;
      font-size: 17px;
      z-index: 10;
      text-align: center;
      max-width: 90%;
    }
    #controls {
      position: fixed;
      bottom: 40px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 10;
      display: flex;
      flex-direction: column;
      gap: 15px;
      align-items: center;
    }
    button {
      padding: 18px 35px;
      background: rgba(0, 122, 255, 0.95);
      color: white;
      border: none;
      border-radius: 30px;
      font-size: 18px;
      font-weight: 600;
      min-width: 200px;
    }
    .secondary-btn {
      background: rgba(255, 255, 255, 0.2);
      padding: 12px 25px;
      font-size: 15px;
      min-width: auto;
    }
    .hidden {
      display: none;
    }
    #stats {
      position: fixed;
      top: 70px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0,0,0,0.7);
      padding: 10px 20px;
      border-radius: 15px;
      font-size: 14px;
      z-index: 10;
    }
    .value {
      color: #0ff;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <div id="container">
    <div id="loading">Loading AI model...</div>
    <div id="stats" class="hidden">
      People: <span id="peopleCount" class="value">0</span> | 
      FPS: <span id="fps" class="value">0</span> |
      Keypoints: <span id="keypointCount" class="value">0</span>
    </div>
    <video id="video" playsinline autoplay muted></video>
    <canvas id="canvas"></canvas>
    <div id="controls">
      <button id="startBtn">Start Camera</button>
      <button id="flipBtn" class="secondary-btn hidden">Flip Camera</button>
    </div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const loadingEl = document.getElementById("loading");
    const startBtn = document.getElementById("startBtn");
    const flipBtn = document.getElementById("flipBtn");
    const statsEl = document.getElementById("stats");
    const fpsEl = document.getElementById("fps");
    const peopleCountEl = document.getElementById("peopleCount");
    const keypointCountEl = document.getElementById("keypointCount");
    
    let net = null;
    let previousKeypoints = null;
    const smoothingFactor = 0.5;
    let isRunning = false;
    let facingMode = 'user';
    let stream = null;
    let minConfidence = 0.3;
    
    let lastFrameTime = Date.now();
    let frameCount = 0;

    async function setupCamera() {
      loadingEl.textContent = "Starting camera...";
      
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      
      stream = await navigator.mediaDevices.getUserMedia({
        audio: false,
        video: { 
          facingMode: facingMode,
          width: { ideal: 640 },
          height: { ideal: 480 }
        },
      });
      
      video.srcObject = stream;
      
      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          video.play();
          setTimeout(() => {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            
            console.log("Video:", video.videoWidth, "x", video.videoHeight);
            console.log("Canvas:", canvas.width, "x", canvas.height);
            console.log("Window:", window.innerWidth, "x", window.innerHeight);
            
            resolve();
          }, 500);
        };
      });
    }

    function smoothKeypoints(keypoints) {
      if (!previousKeypoints) {
        previousKeypoints = keypoints.map(kp => ({...kp, position: {...kp.position}}));
        return keypoints;
      }

      const smoothed = keypoints.map((kp, i) => {
        const prev = previousKeypoints[i];
        if (!prev) return kp;

        return {
          ...kp,
          position: {
            x: prev.position.x * smoothingFactor + kp.position.x * (1 - smoothingFactor),
            y: prev.position.y * smoothingFactor + kp.position.y * (1 - smoothingFactor)
          }
        };
      });

      previousKeypoints = smoothed.map(kp => ({...kp, position: {...kp.position}}));
      return smoothed;
    }

    function drawFrame() {
      // Draw video frame mirrored
      ctx.save();
      ctx.scale(-1, 1);
      ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
      ctx.restore();
    }

    function drawKeypoints(keypoints, minConf, ctx) {
      let count = 0;
      
      // Calculate scale from video to canvas
      const scaleX = canvas.width / video.videoWidth;
      const scaleY = canvas.height / video.videoHeight;
      
      keypoints.forEach((kp, index) => {
        if (kp.score < minConf) return;
        count++;
        
        let { y, x } = kp.position;
        
        // Scale to canvas size
        x = x * scaleX;
        y = y * scaleY;
        
        // Mirror horizontally
        x = canvas.width - x;
        
        if (index === 0) {
          console.log(`Keypoint 0: Original(${kp.position.x.toFixed(0)}, ${kp.position.y.toFixed(0)}) -> Scaled(${x.toFixed(0)}, ${y.toFixed(0)})`);
        }
        
        // Draw big visible keypoint
        ctx.beginPath();
        ctx.arc(x, y, 20, 0, 2 * Math.PI);
        ctx.fillStyle = '#00ff00';
        ctx.fill();
        ctx.strokeStyle = '#ffffff';
        ctx.lineWidth = 6;
        ctx.stroke();
      });
      
      return count;
    }

    function drawSkeleton(keypoints, minConf, ctx) {
      const adjacentKeyPoints = posenet.getAdjacentKeyPoints(keypoints, minConf);
      
      const scaleX = canvas.width / video.videoWidth;
      const scaleY = canvas.height / video.videoHeight;
      
      adjacentKeyPoints.forEach(([kp1, kp2]) => {
        let x1 = kp1.position.x * scaleX;
        let y1 = kp1.position.y * scaleY;
        let x2 = kp2.position.x * scaleX;
        let y2 = kp2.position.y * scaleY;
        
        // Mirror horizontally
        x1 = canvas.width - x1;
        x2 = canvas.width - x2;
        
        ctx.beginPath();
        ctx.moveTo(x1, y1);
        ctx.lineTo(x2, y2);
        ctx.lineWidth = 10;
        ctx.strokeStyle = '#00ffff';
        ctx.stroke();
      });
      
      console.log("Drew", adjacentKeyPoints.length, "skeleton lines");
    }

    function updateFPS() {
      frameCount++;
      const now = Date.now();
      const elapsed = now - lastFrameTime;
      
      if (elapsed >= 1000) {
        const fps = Math.round((frameCount * 1000) / elapsed);
        fpsEl.textContent = fps;
        frameCount = 0;
        lastFrameTime = now;
      }
    }

    async function detectPose() {
      if (!net || !isRunning) return;
      
      const pose = await net.estimateSinglePose(video, {
        flipHorizontal: false,
      });
      
      const smoothedKeypoints = smoothKeypoints(pose.keypoints);

      peopleCountEl.textContent = pose.score > 0.1 ? "1" : "0";

      // Clear canvas
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      
      // Draw video frame
      drawFrame();
      
      // Draw pose
      const keypointCount = drawKeypoints(smoothedKeypoints, minConfidence, ctx);
      drawSkeleton(smoothedKeypoints, minConfidence, ctx);
      
      keypointCountEl.textContent = keypointCount;
      
      updateFPS();
      requestAnimationFrame(detectPose);
    }

    startBtn.addEventListener('click', async () => {
      try {
        startBtn.disabled = true;
        await setupCamera();
        loadingEl.textContent = "Move around! ðŸ‘‹";
        statsEl.classList.remove('hidden');
        flipBtn.classList.remove('hidden');
        startBtn.classList.add('hidden');
        isRunning = true;
        detectPose();
      } catch (err) {
        console.error("Error:", err);
        loadingEl.textContent = "Error: " + err.message;
        startBtn.disabled = false;
      }
    });

    flipBtn.addEventListener('click', async () => {
      facingMode = facingMode === 'user' ? 'environment' : 'user';
      previousKeypoints = null;
      await setupCamera();
    });

    window.addEventListener('resize', () => {
      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;
    });

    async function init() {
      try {
        loadingEl.textContent = "Loading AI model...";
        
        net = await posenet.load({
          architecture: "MobileNetV1",
          outputStride: 16,
          inputResolution: { width: 640, height: 480 },
          multiplier: 0.75,
        });

        loadingEl.textContent = "Ready! Tap Start Camera";
        startBtn.disabled = false;
      } catch (err) {
        console.error("Error:", err);
        loadingEl.textContent = "Error loading model";
      }
    }

    init();
  </script>
</body>
</html>
